{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import datetime \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "    aligned_frames = align.process(frame)\n",
    "\n",
    "    #depth_frame = frames.get_depth_frame()\n",
    "    #color_frame = frames.get_color_frame()\n",
    "\n",
    "    # Get the aligned color and depth frames\n",
    "    aligned_color_frame = aligned_frames.get_color_frame()\n",
    "    aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "    # Put images in the code\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "    cv2.putText(color_image, depth_text, (xaxis+10, yaxis-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    #plt.imshow(gray_image)\n",
    "    #plt.scatter(xaxis, yaxis, color='red', marker='x')  # Mark the point (20, 20) with a red 'x'\n",
    "    #plt.axis('off')  # Optional, to turn off the axis labels\n",
    "    #plt.show()\n",
    "\n",
    "    # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    print(f\"Depth at ({xaxis}, {yaxis}): {depth_value} meters\")\n",
    "\n",
    "pipe.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "# define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# init. the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "# start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# it is a good practice to wait a few frames before the main stream\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw a marker at (xaxis, yaxis) on the color image\n",
    "        cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "        depth_value = aligned_depth_frame.get_distance(xaxis, yaxis)\n",
    "        depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "        cv2.putText(color_image, depth_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "        if pressed_key == ord('s'):\n",
    "            # Save image or perform other actions\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inittialize vars and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now detection of 2 points that are not hardcoded and have the same color and the euclidean distance between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of last 10 frames\n",
    "\n",
    "def stabilization_values(last_depth_values: list, depth_value: float) -> float:\n",
    "    # Add the depth value to the list and remove the oldest one if the list has more than 10 items\n",
    "    last_depth_values.append(depth_value)\n",
    "    if len(last_depth_values) > 50:\n",
    "        last_depth_values.pop(0)\n",
    "\n",
    "    # Calculate the mean depth value\n",
    "    mean_depth_value = sum(last_depth_values) / len(last_depth_values)\n",
    "\n",
    "    return mean_depth_value, last_depth_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(frame_count: int, color_mtx, depth_mtx) -> None:\n",
    "    # Save frames every 100 frames\n",
    "    if frame_count % 100 == 0:\n",
    "        np.save(f'color_{frame_count}.npy', color_mtx)\n",
    "        np.save(f'depth_{frame_count}.npy', depth_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "xaxis = 320\n",
    "yaxis = 240\n",
    "width = 848\n",
    "height = 480\n",
    "scale_multiplier = 1 #0.91\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "last_frame_values_depth = []\n",
    "display_point = None\n",
    "display_text = \"\"\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# Callback function for mouse click\n",
    "# TODO: correct the mean depth value calculation when the mouse is clicked\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global display_point, display_text, last_frame_values_depth, mean_depth_value\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i in range(2):\n",
    "            depth_value = aligned_depth_frame.get_distance(x, y) * scale_multiplier\n",
    "            display_point = (x, y)\n",
    "            display_text = f\"Distance: {depth_value:.2f} meters\"\n",
    "            time.sleep(1)\n",
    "\n",
    "cv2.namedWindow('dual_win')\n",
    "cv2.setMouseCallback('dual_win', mouse_click)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        color_mtx = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_mtx = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_mtx, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        #cv2.drawMarker(color_mtx, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        show_dual_win = np.hstack((color_mtx,depth_colormap))\n",
    "        \n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if pressed_key == ord('q'):\n",
    "            break\n",
    "            \n",
    "        if pressed_key == ord('s'):\n",
    "            break\n",
    "\n",
    "        # Display the cross marker and distance at the last clicked location\n",
    "        if display_point is not None:\n",
    "            cv2.drawMarker(show_dual_win, display_point, (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "            cv2.putText(show_dual_win, display_text, (display_point[0] + 10, display_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "        mean_depth_value, last_frame_values_depth = stabilization_values(last_frame_values_depth, depth_value)\n",
    "\n",
    "        cv2.imshow('dual_win', show_dual_win)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "frame_count = len(os.listdir()) // 2  # Divide by 2 because we have color and depth frames\n",
    "xaxis = 320\n",
    "yaxis = 240\n",
    "\n",
    "try:\n",
    "    for i in range(100, 500, 100):  # multiply frame_count by 100 because we saved frames every 100 frames\n",
    "        color_frame = np.load(f'color_{i}.npy')\n",
    "        depth_frame = np.load(f'depth_{i}.npy')\n",
    "\n",
    "        depth_value = depth_frame[yaxis, xaxis]\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {depth_value:.2f} meters\"\n",
    "        cv2.putText(color_frame, distance_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('color_frame', color_frame)\n",
    "\n",
    "        if cv2.waitKey(66) & 0xFF == ord('q'):  # Delay of 66 ms for approx 15 fps\n",
    "            break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
