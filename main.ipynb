{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.0 meters\n",
      "Depth at (200, 20): 0.9810000658035278 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9820000529289246 meters\n",
      "Depth at (200, 20): 0.9810000658035278 meters\n",
      "Depth at (200, 20): 0.987000048160553 meters\n",
      "Depth at (200, 20): 0.9810000658035278 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.9780000448226929 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.9780000448226929 meters\n",
      "Depth at (200, 20): 0.9890000224113464 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.9820000529289246 meters\n",
      "Depth at (200, 20): 0.9920000433921814 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9790000319480896 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.987000048160553 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.987000048160553 meters\n",
      "Depth at (200, 20): 0.9900000691413879 meters\n",
      "Depth at (200, 20): 0.9850000739097595 meters\n",
      "Depth at (200, 20): 0.9920000433921814 meters\n",
      "Depth at (200, 20): 0.987000048160553 meters\n",
      "Depth at (200, 20): 0.984000027179718 meters\n",
      "Depth at (200, 20): 0.9780000448226929 meters\n",
      "Depth at (200, 20): 0.987000048160553 meters\n",
      "Depth at (200, 20): 0.9810000658035278 meters\n",
      "Depth at (200, 20): 0.9780000448226929 meters\n",
      "Depth at (200, 20): 0.9950000643730164 meters\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import datetime \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "    aligned_frames = align.process(frame)\n",
    "\n",
    "    #depth_frame = frames.get_depth_frame()\n",
    "    #color_frame = frames.get_color_frame()\n",
    "\n",
    "    # Get the aligned color and depth frames\n",
    "    aligned_color_frame = aligned_frames.get_color_frame()\n",
    "    aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "    # Put images in the code\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "    cv2.putText(color_image, depth_text, (xaxis+10, yaxis-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    #plt.imshow(gray_image)\n",
    "    #plt.scatter(xaxis, yaxis, color='red', marker='x')  # Mark the point (20, 20) with a red 'x'\n",
    "    #plt.axis('off')  # Optional, to turn off the axis labels\n",
    "    #plt.show()\n",
    "\n",
    "    # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    print(f\"Depth at ({xaxis}, {yaxis}): {depth_value} meters\")\n",
    "\n",
    "pipe.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "# define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# init. the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "# start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# it is a good practice to wait a few frames before the main stream\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw a marker at (xaxis, yaxis) on the color image\n",
    "        cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "        depth_value = aligned_depth_frame.get_distance(xaxis, yaxis)\n",
    "        depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "        cv2.putText(color_image, depth_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "        if pressed_key == ord('s'):\n",
    "            # Save image or perform other actions\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inittialize vars and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now detection of 2 points that are not hardcoded and have the same color and the euclidean distance between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stop() cannot be called before start()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 39\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     frames \u001b[39m=\u001b[39m pipeline\u001b[39m.\u001b[39;49mwait_for_frames()\n\u001b[0;32m     41\u001b[0m     \u001b[39m# Align the frames\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Device disconnected. Failed to reconnect: No device connected5000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 91\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m---> 91\u001b[0m     pipeline\u001b[39m.\u001b[39;49mstop()\n\u001b[0;32m     92\u001b[0m     cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stop() cannot be called before start()"
     ]
    }
   ],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of last 10 frames\n",
    "\n",
    "def stabilization_values(last_depth_values: list, depth_value: float) -> float:\n",
    "    # Add the depth value to the list and remove the oldest one if the list has more than 10 items\n",
    "    last_depth_values.append(depth_value)\n",
    "    if len(last_depth_values) > 30:\n",
    "        last_depth_values.pop(0)\n",
    "\n",
    "    # Calculate the mean depth value\n",
    "    mean_depth_value = sum(last_depth_values) / len(last_depth_values)\n",
    "\n",
    "    return mean_depth_value, last_depth_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basics of pyrealsense2 (BGR, Depth)\n",
    "\n",
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "xaxis = 320\n",
    "\n",
    "yaxis = 240\n",
    "\n",
    "# define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# init. the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "# start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# It is a good practice to wait a few frames before the main steam\n",
    "for _ in range(10):\n",
    "    frame = pipeline.wait_for_frames()\n",
    "\n",
    "# Initialization of last frame values\n",
    "last_frame_values_depth = []\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        \n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "        \n",
    "        #get BGR  and Depth data, then create a depth colorized image\n",
    "        color_mtx = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_mtx = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_mtx, alpha=0.03), cv2.COLORMAP_JET)\n",
    "        # stack the two images\n",
    "        cv2.drawMarker(color_mtx, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        show_dual_win = np.hstack((color_mtx,depth_colormap))\n",
    "        \n",
    "        # show BGR and Depth image\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if pressed_key == ord('q'):\n",
    "            # quit\n",
    "            break\n",
    "            \n",
    "        if pressed_key == ord('s'):\n",
    "            # can save image or anything\n",
    "            break\n",
    "\n",
    "        depth_value = aligned_depth_frame.get_distance(xaxis, yaxis)\n",
    "        mean_depth_value, last_frame_values_depth = stabilization_values(last_frame_values_depth, depth_value)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {mean_depth_value:.2f} meters\"\n",
    "        cv2.putText(show_dual_win, distance_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('dual_win', show_dual_win)\n",
    "\n",
    "\n",
    "        #print coordinates\n",
    "        #depth_intrinsics = aligned_depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "        #depth_value = aligned_depth_frame.get_distance(xaxis, yaxis)\n",
    "        #point_3D = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [xaxis, yaxis], depth_value)\n",
    "        #print(\"3D point at pixel ({}, {}): {}\".format(xaxis, yaxis, point_3D))\n",
    "        \n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
