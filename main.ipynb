{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.125 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1230000257492065 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.125 meters\n",
      "Depth at (200, 20): 1.1170001029968262 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1610000133514404 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.125 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1630001068115234 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1660000085830688 meters\n",
      "Depth at (200, 20): 1.1190000772476196 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1170001029968262 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1700000762939453 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1230000257492065 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.125 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1170001029968262 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1660000085830688 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1630001068115234 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1630001068115234 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1660000085830688 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1610000133514404 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.15500009059906 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1230000257492065 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1630001068115234 meters\n",
      "Depth at (200, 20): 1.125 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1720000505447388 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1230000257492065 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1610000133514404 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.1110000610351562 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1290000677108765 meters\n",
      "Depth at (200, 20): 1.13100004196167 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.1330000162124634 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1570000648498535 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1440000534057617 meters\n",
      "Depth at (200, 20): 1.159000039100647 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.1610000133514404 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.1630001068115234 meters\n",
      "Depth at (200, 20): 1.1370000839233398 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1460000276565552 meters\n",
      "Depth at (200, 20): 1.1420000791549683 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1500000953674316 meters\n",
      "Depth at (200, 20): 1.152000069618225 meters\n",
      "Depth at (200, 20): 1.1350001096725464 meters\n",
      "Depth at (200, 20): 1.127000093460083 meters\n",
      "Depth at (200, 20): 1.1480000019073486 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n",
      "Depth at (200, 20): 1.1400001049041748 meters\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m frame \u001b[39m=\u001b[39m pipe\u001b[39m.\u001b[39mwait_for_frames()\n\u001b[0;32m     25\u001b[0m     \u001b[39m# Align the frames\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m aligned_frames \u001b[39m=\u001b[39m align\u001b[39m.\u001b[39mprocess(frame)\n\u001b[0;32m     28\u001b[0m \u001b[39m#depth_frame = frames.get_depth_frame()\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[39m#color_frame = frames.get_color_frame()\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[39m# Get the aligned color and depth frames\u001b[39;00m\n\u001b[0;32m     32\u001b[0m aligned_color_frame \u001b[39m=\u001b[39m aligned_frames\u001b[39m.\u001b[39mget_color_frame()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import datetime \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "    aligned_frames = align.process(frame)\n",
    "\n",
    "    #depth_frame = frames.get_depth_frame()\n",
    "    #color_frame = frames.get_color_frame()\n",
    "\n",
    "    # Get the aligned color and depth frames\n",
    "    aligned_color_frame = aligned_frames.get_color_frame()\n",
    "    aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "    # Put images in the code\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "    cv2.putText(color_image, depth_text, (xaxis+10, yaxis-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "\n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    #plt.imshow(gray_image)\n",
    "    #plt.scatter(xaxis, yaxis, color='red', marker='x')  # Mark the point (20, 20) with a red 'x'\n",
    "    #plt.axis('off')  # Optional, to turn off the axis labels\n",
    "    #plt.show()\n",
    "\n",
    "    # Get depth at coordinates (xaxis, yaxis)\n",
    "    depth_value = depth_frame.get_distance(xaxis, yaxis)\n",
    "    print(f\"Depth at ({xaxis}, {yaxis}): {depth_value} meters\")\n",
    "\n",
    "pipe.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LUCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m# Show the color image with depth information\u001b[39;00m\n\u001b[0;32m     66\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDual Window\u001b[39m\u001b[39m'\u001b[39m, show_dual_win)\n\u001b[1;32m---> 68\u001b[0m pressed_key \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m pressed_key \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     71\u001b[0m     \u001b[39m# Quit\u001b[39;00m\n\u001b[0;32m     72\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "xaxis = 200\n",
    "yaxis = 20\n",
    "\n",
    "# define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# init. the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "# camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "# start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# it is a good practice to wait a few frames before the main stream\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frame_count += 1\n",
    "\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw a marker at (xaxis, yaxis) on the color image\n",
    "        cv2.drawMarker(color_image, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth at coordinates (xaxis, yaxis)\n",
    "        depth_value = aligned_depth_frame.get_distance(xaxis, yaxis)\n",
    "        depth_text = f\"Depth: {depth_value:.2f} meters\"\n",
    "        cv2.putText(color_image, depth_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        save_data(frame_count, depth_colormap, depth_value)\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "        if pressed_key == ord('s'):\n",
    "            # Save image or perform other actions\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inittialize vars and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now detection of 2 points that are not hardcoded and have the same color and the euclidean distance between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39m# Show the color image with depth information\u001b[39;00m\n\u001b[0;32m     84\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDual Window\u001b[39m\u001b[39m'\u001b[39m, show_dual_win)\n\u001b[1;32m---> 86\u001b[0m pressed_key \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m pressed_key \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     89\u001b[0m     \u001b[39m# Quit\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Coordinates of the two points\n",
    "x1, y1 = 200, 20\n",
    "x2, y2 = 200, 200\n",
    "\n",
    "# Define the screen size\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Initialize the camera pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Camera settings\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "\n",
    "# Start the camera pipeline\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "# Wait for a few frames before the main stream\n",
    "# This is to allow the camera time to adjust its brightness and other camera settings and stabilize\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "# Intrinsics are used to get the depth scale\n",
    "\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_profile = rs.video_stream_profile(profile.get_stream(rs.stream.depth))\n",
    "depth_intrinsics = depth_profile.get_intrinsics()\n",
    "depth_scale = profile.get_device().first_depth_sensor().get_depth_scale()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "\n",
    "        # Align the frames\n",
    "        aligned_frames = align.process(frames)\n",
    "\n",
    "        # Get the aligned color and depth frames\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # Get BGR and Depth data, then create a depth colorized image\n",
    "        color_image = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_image = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        # Draw markers at the two points on the color image\n",
    "        cv2.drawMarker(color_image, (x1, y1), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        cv2.drawMarker(color_image, (x2, y2), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "\n",
    "        # Get depth values at the two points\n",
    "        depth_value1 = aligned_depth_frame.get_distance(x1, y1)\n",
    "        depth_value2 = aligned_depth_frame.get_distance(x2, y2)\n",
    "\n",
    "        # Convert from pixel coordinates to real world coordinates \n",
    "        point1 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x1, y1], depth_value1)\n",
    "        point2 = rs.rs2_deproject_pixel_to_point(depth_intrinsics, [x2, y2], depth_value2)\n",
    "\n",
    "        # Calculate the euclidean distance between the two points with depth values as z coordinates\n",
    "        diff = np.subtract(point1, point2)\n",
    "        euclidean_distance = np.linalg.norm(diff)\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {euclidean_distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (x1 + 10, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        # Trace a line between the two points\n",
    "        cv2.line(color_image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "        # Stack the color image and depth colormap\n",
    "        show_dual_win = np.hstack((color_image, depth_colormap))\n",
    "\n",
    "        \n",
    "        # Show the color image with depth information\n",
    "        cv2.imshow('Dual Window', show_dual_win)\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean of last 10 frames\n",
    "\n",
    "def stabilization_values(last_depth_values: list, depth_value: float) -> float:\n",
    "    # Add the depth value to the list and remove the oldest one if the list has more than 10 items\n",
    "    last_depth_values.append(depth_value)\n",
    "    if len(last_depth_values) > 50:\n",
    "        last_depth_values.pop(0)\n",
    "\n",
    "    # Calculate the mean depth value\n",
    "    mean_depth_value = sum(last_depth_values) / len(last_depth_values)\n",
    "\n",
    "    return mean_depth_value, last_depth_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2369773669.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    np.save(f'color_{frame_count}.npy', color_mtx)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def save_data(frame_count: int, color_mtx, depth_mtx) -> None:\n",
    "    # Save frames every 100 frames\n",
    "    if frame_count % 100 == 0:x\n",
    "        np.save(f'color_{frame_count}.npy', color_mtx)\n",
    "        np.save(f'depth_{frame_count}.npy', depth_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stabilization_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m             cv2\u001b[39m.\u001b[39mdrawMarker(show_dual_win, display_point, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m), markerType\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mMARKER_CROSS, markerSize\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, thickness\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     67\u001b[0m             cv2\u001b[39m.\u001b[39mputText(show_dual_win, display_text, (display_point[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m10\u001b[39m, display_point[\u001b[39m1\u001b[39m] \u001b[39m-\u001b[39m \u001b[39m10\u001b[39m), cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[39m0.5\u001b[39m, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m255\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m         mean_depth_value, last_frame_values_depth \u001b[39m=\u001b[39m stabilization_values(last_frame_values_depth, depth_value)\n\u001b[0;32m     71\u001b[0m         cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mdual_win\u001b[39m\u001b[39m'\u001b[39m, show_dual_win)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stabilization_values' is not defined"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "xaxis = 320\n",
    "yaxis = 240\n",
    "width = 848\n",
    "height = 480\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "last_frame_values_depth = []\n",
    "display_point = None\n",
    "display_text = \"\"\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# Callback function for mouse click\n",
    "# TODO: correct the mean depth value calculation when the mouse is clicked\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global display_point, display_text, last_frame_values_depth, mean_depth_value\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i in range(2):\n",
    "            depth_value = aligned_depth_frame.get_distance(x, y) \n",
    "            display_point = (x, y)\n",
    "            display_text = f\"Distance: {depth_value:.2f} meters\"\n",
    "            time.sleep(1)\n",
    "\n",
    "cv2.namedWindow('dual_win')\n",
    "cv2.setMouseCallback('dual_win', mouse_click)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        color_mtx = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_mtx = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_mtx, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        #cv2.drawMarker(color_mtx, (xaxis, yaxis), (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "        show_dual_win = np.hstack((color_mtx,depth_colormap))\n",
    "        \n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "        \n",
    "        if pressed_key == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Display the cross marker and distance at the last clicked location\n",
    "        if display_point is not None:\n",
    "            cv2.drawMarker(show_dual_win, display_point, (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "            cv2.putText(show_dual_win, display_text, (display_point[0] + 10, display_point[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "        \n",
    "        mean_depth_value, last_frame_values_depth = stabilization_values(last_frame_values_depth, depth_value)\n",
    "\n",
    "        cv2.imshow('dual_win', show_dual_win)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "frame_count = len(os.listdir()) // 2  # Divide by 2 because we have color and depth frames\n",
    "xaxis = 320\n",
    "yaxis = 240\n",
    "\n",
    "try:\n",
    "    for i in range(100, 500, 100):  # multiply frame_count by 100 because we saved frames every 100 frames\n",
    "        color_frame = np.load(f'color_{i}.npy')\n",
    "        depth_frame = np.load(f'depth_{i}.npy')\n",
    "\n",
    "        depth_value = depth_frame[yaxis, xaxis]\n",
    "\n",
    "        # Display the distance on the color image\n",
    "        distance_text = f\"Distance: {depth_value:.2f} meters\"\n",
    "        cv2.putText(color_frame, distance_text, (xaxis + 10, yaxis - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('color_frame', color_frame)\n",
    "\n",
    "        if cv2.waitKey(66) & 0xFF == ord('q'):  # Delay of 66 ms for approx 15 fps\n",
    "            break\n",
    "finally:\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "\n",
    "# Load COCO class names\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "unconnected_out_layers = net.getUnconnectedOutLayers()\n",
    "\n",
    "if len(unconnected_out_layers.shape) == 2:  # Shape (n, 1) - OpenCV 3.x\n",
    "    output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]\n",
    "else:  # Shape (n,) - OpenCV 4.x\n",
    "    output_layers = [layer_names[i - 1] for i in unconnected_out_layers]\n",
    "\n",
    "# Load the video\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "try:\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        height, width, channels = frame.shape\n",
    "\n",
    "        \n",
    "\n",
    "        # Detect objects\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Show information on screen\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # We use NMS function in opencv to perform Non-maximum Suppression\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        # We draw bounding boxes and labels of detection\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(class_ids[i])\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                label = f\"{class_names[class_ids[i]]}: {confidences[i]:.2f}\"  # use class_ids[i] and confidences[i]\n",
    "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.imshow(\"Video\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "xaxis = 320\n",
    "yaxis = 240\n",
    "width = 848\n",
    "height = 480\n",
    "\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "pipeline.start(config)\n",
    "\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "last_frame_values_depth = []\n",
    "display_point = None\n",
    "display_text = \"\"\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# Callback function for mouse click\n",
    "# TODO: correct the mean depth value calculation when the mouse is clicked\n",
    "def mouse_click(event, x, y, flags, param):\n",
    "    global display_point, display_text, last_frame_values_depth, mean_depth_value\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i in range(2):\n",
    "            depth_value = aligned_depth_frame.get_distance(x, y)\n",
    "            display_point = (x, y)\n",
    "            display_text = f\"Distance: {depth_value:.2f} meters\"\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "cv2.namedWindow('dual_win')\n",
    "cv2.setMouseCallback('dual_win', mouse_click)\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet(\"models/yolov3.weights\", \"models/yolov3.cfg\")\n",
    "\n",
    "# Load COCO class names\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    class_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "unconnected_out_layers = net.getUnconnectedOutLayers()\n",
    "\n",
    "if len(unconnected_out_layers.shape) == 2:  # Shape (n, 1) - OpenCV 3.x\n",
    "    output_layers = [layer_names[i[0] - 1] for i in unconnected_out_layers]\n",
    "else:  # Shape (n,) - OpenCV 4.x\n",
    "    output_layers = [layer_names[i - 1] for i in unconnected_out_layers]\n",
    "\n",
    "# Define video writer parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_file = cv2.VideoWriter('yolo_try5.mp4', fourcc, 15.0, (2 * width, height))\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        aligned_frames = align.process(frames)\n",
    "        aligned_color_frame = aligned_frames.get_color_frame()\n",
    "        aligned_depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "        if not aligned_depth_frame or not aligned_color_frame:\n",
    "            continue\n",
    "\n",
    "        color_mtx = np.asanyarray(aligned_color_frame.get_data())\n",
    "        depth_mtx = np.asanyarray(aligned_depth_frame.get_data())\n",
    "        depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_mtx, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Detect objects using YOLO\n",
    "        blob = cv2.dnn.blobFromImage(color_mtx, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Show information on screen\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    # Object detected\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Rectangle coordinates\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Perform non-maximum suppression\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        # Draw bounding boxes and labels\n",
    "        for i in range(len(boxes)):\n",
    "            if i in indexes:\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = f\"{class_names[class_ids[i]]}: {confidences[i]:.2f}\"\n",
    "                cv2.rectangle(color_mtx, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                cv2.putText(color_mtx, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "        show_dual_win = np.hstack((color_mtx, depth_colormap))\n",
    "\n",
    "        pressed_key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if pressed_key == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Display the cross marker and distance at the last clicked location\n",
    "        if display_point is not None:\n",
    "            cv2.drawMarker(show_dual_win, display_point, (0, 0, 255), markerType=cv2.MARKER_CROSS, markerSize=10, thickness=2)\n",
    "            cv2.putText(show_dual_win, display_text, (display_point[0] + 10, display_point[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('dual_win', show_dual_win)\n",
    "\n",
    "        # Save the frame to the video file\n",
    "        output_file.write(show_dual_win)\n",
    "\n",
    "finally:\n",
    "    pipeline.stop()\n",
    "    output_file.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection of red rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo_b\\AppData\\Local\\Temp\\ipykernel_17836\\3568115185.py:89: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Video frame dimensions\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# Color range for red rectangle detection (in HSV color space)\n",
    "lower_red = np.array([0, 100, 100])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([160, 100, 100])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "# Lists for tracking the depth values\n",
    "last_depth_values1 = []\n",
    "last_depth_values2 = []\n",
    "last_depth_values_between = []\n",
    "\n",
    "cv2.namedWindow('Color Image')\n",
    "# Define video writer parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_file = cv2.VideoWriter('rectangles_4.mp4', fourcc, 30.0, (width, height))\n",
    "\n",
    "\n",
    "# Check if the output video file is open\n",
    "if not output_file.isOpened():\n",
    "    print(\"Error: Unable to open output video file\")\n",
    "    exit()\n",
    "# Main loop\n",
    "while True:\n",
    "    # Wait for a coherent pair of frames: color and depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    # Align the frames\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    # Get the aligned color and depth frames\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "    if not color_frame or not depth_frame:\n",
    "        continue\n",
    "\n",
    "    # Convert color image to numpy array\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Convert color image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for red objects\n",
    "    mask_red = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "    mask_red2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "    mask_red_combined = cv2.bitwise_or(mask_red, mask_red2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask_red_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest and second largest red rectangles\n",
    "    largest_rectangle = None\n",
    "    second_largest_rectangle = None\n",
    "    max_area = 0\n",
    "    second_max_area = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        # Find the minimum area rectangle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        # Calculate the area of the rectangle\n",
    "        area = cv2.contourArea(box)\n",
    "\n",
    "        # Update the largest and second largest rectangles if the area is larger\n",
    "        if area > max_area:\n",
    "            second_largest_rectangle = largest_rectangle\n",
    "            second_max_area = max_area\n",
    "            max_area = area\n",
    "            largest_rectangle = box\n",
    "        elif area > second_max_area:\n",
    "            second_max_area = area\n",
    "            second_largest_rectangle = box\n",
    "\n",
    "    if largest_rectangle is not None:\n",
    "        # Draw the largest rectangle and its corners on the color image\n",
    "        cv2.drawContours(color_image, [largest_rectangle], 0, (0, 0, 255), 2)\n",
    "        for corner in largest_rectangle:\n",
    "            x, y = corner\n",
    "            cv2.circle(color_image, (x, y), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Find the middle point of the rectangle\n",
    "        rect_center = np.mean(largest_rectangle, axis=0)\n",
    "        rect_center_x, rect_center_y = rect_center.astype(int)\n",
    "        cv2.circle(color_image, (rect_center_x, rect_center_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Get the depth value at the middle point\n",
    "        depth_value1 = depth_frame.get_distance(rect_center_x, rect_center_y)\n",
    "\n",
    "        # Convert from pixel coordinates to real-world coordinates\n",
    "        depth_intrinsics = depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "        point1 = np.array(rs.rs2_deproject_pixel_to_point(depth_intrinsics, [rect_center_x, rect_center_y], depth_value1))\n",
    "\n",
    "        # Stabilize the depth value\n",
    "        mean_depth_value1, last_depth_values1 = stabilization_values(last_depth_values1, depth_value1)\n",
    "        \n",
    "        # Display the stabilized distance on the color image\n",
    "        text = f\"Stabilized Distance 1: {mean_depth_value1:.2f} meters\"\n",
    "        cv2.putText(color_image, text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    if second_largest_rectangle is not None:\n",
    "        # Draw the second largest rectangle and its corners on the color image\n",
    "        cv2.drawContours(color_image, [second_largest_rectangle], 0, (0, 255, 0), 2)\n",
    "        for corner in second_largest_rectangle:\n",
    "            x, y = corner\n",
    "            cv2.circle(color_image, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Find the middle point of the second rectangle\n",
    "        second_rect_center = np.mean(second_largest_rectangle, axis=0)\n",
    "        second_rect_center_x, second_rect_center_y = second_rect_center.astype(int)\n",
    "        cv2.circle(color_image, (second_rect_center_x, second_rect_center_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "        # Get the depth value at the middle point\n",
    "        depth_value2 = depth_frame.get_distance(second_rect_center_x, second_rect_center_y)\n",
    "\n",
    "        # Convert from pixel coordinates to real-world coordinates\n",
    "        point2 = np.array(rs.rs2_deproject_pixel_to_point(depth_intrinsics, [second_rect_center_x, second_rect_center_y], depth_value2))\n",
    "\n",
    "    # Stabilize the depth value\n",
    "        mean_depth_value2, last_depth_values2 = stabilization_values(last_depth_values2, depth_value2)\n",
    "        \n",
    "        # Display the stabilized distance on the color image\n",
    "        text = f\"Stabilized Distance 2: {mean_depth_value2 :.2f} meters\"\n",
    "        cv2.putText(color_image, text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # Calculate the Euclidean distance between the two middle points\n",
    "        distance = np.linalg.norm(point2 - point1)\n",
    "\n",
    "        # Display the Euclidean distance between the two middle points on the color image\n",
    "        distance_text = f\"Distance between points: {distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw a line between the two middle points\n",
    "        cv2.line(color_image, (rect_center_x, rect_center_y), (second_rect_center_x, second_rect_center_y), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the color image\n",
    "    cv2.imshow(\"Color Image\", color_image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    output_file.write(color_image)\n",
    "\n",
    "pipeline.stop()\n",
    "output_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tic tac toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "# Configure the streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "# Start streaming\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "\n",
    "# The game state\n",
    "game_state = np.zeros((3, 3), dtype=int)\n",
    "\n",
    "# Mapping from shape to player\n",
    "shape_to_player = {'triangle': 1, 'circle': -1}\n",
    "\n",
    "# A function to update the game state based on a shape's center\n",
    "def update_game_state(shape, center):\n",
    "    player = shape_to_player[shape]\n",
    "    i = int(center[1] // cell_height)\n",
    "    j = int(center[0] // cell_width)\n",
    "    game_state[i, j] = player\n",
    "\n",
    "# A function to check if there's a win\n",
    "def check_win():\n",
    "    # Check rows and columns\n",
    "    for i in range(3):\n",
    "        if abs(sum(game_state[i, :])) == 3 or abs(sum(game_state[:, i])) == 3:\n",
    "            return True\n",
    "    # Check diagonals\n",
    "    if abs(sum(game_state[i, i] for i in range(3))) == 3 or abs(sum(game_state[i, 2 - i] for i in range(3))) == 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "cv2.namedWindow('Color Image')\n",
    "# Define video writer parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_file = cv2.VideoWriter('tictactoe.mp4', fourcc, 30.0, (width, height))\n",
    "\n",
    "\n",
    "# Check if the output video file is open\n",
    "if not output_file.isOpened():\n",
    "    print(\"Error: Unable to open output video file\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Wait for a new set of frames: depth and color\n",
    "        frames = pipeline.wait_for_frames()\n",
    "        color_frame = frames.get_color_frame()\n",
    "\n",
    "        if not color_frame:\n",
    "            continue\n",
    "\n",
    "        # Convert color image to numpy array\n",
    "        color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "                # Calculate the size of each grid cell\n",
    "        height, width, _ = color_image.shape\n",
    "        cell_width = width // 3\n",
    "        cell_height = height // 3\n",
    "\n",
    "        # Draw vertical lines\n",
    "        for i in range(1, 3):\n",
    "            cv2.line(color_image, (i * cell_width, 0), (i * cell_width, height), (255, 255, 255), 2)\n",
    "\n",
    "        # Draw horizontal lines\n",
    "        for i in range(1, 3):\n",
    "            cv2.line(color_image, (0, i * cell_height), (width, i * cell_height), (255, 255, 255), 2)\n",
    "        \n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply Gaussian blur for smoothing\n",
    "        blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        # Apply edge detection\n",
    "        edges = cv2.Canny(blur, 50, 150, apertureSize=3)\n",
    "\n",
    "        # Find contours in the image\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        shape_centers = {'triangle': [], 'circle': []}\n",
    "\n",
    "        for cnt in contours:\n",
    "            # Get contour area\n",
    "            area = cv2.contourArea(cnt)\n",
    "\n",
    "            # Ignore small contours\n",
    "            if area < 400:\n",
    "                continue\n",
    "\n",
    "            # Find the perimeter of contour\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "\n",
    "            # Get approximate polygon\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 3:\n",
    "                x, y = np.average(approx, axis=0)[0]\n",
    "                shape_centers['triangle'].append((x, y))\n",
    "                cv2.drawContours(color_image, [approx], 0, (0, 255, 0), 5)\n",
    "                cv2.putText(color_image, \"Triangle\", (int(x), int(y) - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Fit an ellipse if contour has more than 5 points\n",
    "                if len(approx) > 5:\n",
    "                    ellipse = cv2.fitEllipse(approx)\n",
    "                    x, y = np.average(approx, axis=0)[0]\n",
    "                    shape_centers['circle'].append((x, y))\n",
    "                    cv2.ellipse(color_image, ellipse, (0, 0, 255), 2)\n",
    "                    cv2.putText(color_image, \"Circle\", (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "\n",
    "        # In your loop where you detect shapes, update the game state\n",
    "        for shape in shape_centers:\n",
    "            for center in shape_centers[shape]:\n",
    "                update_game_state(shape, center)\n",
    "        \n",
    "        if check_win():\n",
    "            cv2.putText(color_image, \"WINNER!\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 255), 2)    \n",
    "\n",
    "        # Show image\n",
    "        cv2.imshow('Shapes detection', color_image)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        output_file.write(color_image)\n",
    "\n",
    "\n",
    "finally:\n",
    "    # Stop streaming\n",
    "    pipeline.stop()\n",
    "    output_file.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitagoras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leo_b\\AppData\\Local\\Temp\\ipykernel_17836\\949684978.py:98: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box = np.int0(box)\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Video frame dimensions\n",
    "width = 640\n",
    "height = 480\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, width, height, rs.format.bgr8, 30)\n",
    "config.enable_stream(rs.stream.depth, width, height, rs.format.z16, 30)\n",
    "\n",
    "# Start streaming\n",
    "pipeline.start(config)\n",
    "\n",
    "# Create an align object\n",
    "align_to = rs.stream.color\n",
    "align = rs.align(align_to)\n",
    "\n",
    "for _ in range(10):\n",
    "    pipeline.wait_for_frames()\n",
    "\n",
    "# Get depth scale for converting the depth values to meters\n",
    "profile = pipeline.get_active_profile()\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# Color range for red rectangle detection (in HSV color space)\n",
    "lower_red = np.array([0, 100, 100])\n",
    "upper_red = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([160, 100, 100])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "# Lists for tracking the depth values\n",
    "last_depth_values1 = []\n",
    "last_depth_values2 = []\n",
    "last_depth_values3 = []  # New list for third point\n",
    "last_depth_values_between = []\n",
    "\n",
    "# Find the largest, second largest and third largest red rectangles\n",
    "largest_rectangle = None\n",
    "second_largest_rectangle = None\n",
    "third_largest_rectangle = None  # New variable for third rectangle\n",
    "max_area = 0\n",
    "second_max_area = 0\n",
    "third_max_area = 0  # New variable for third area\n",
    "\n",
    "cv2.namedWindow('Color Image')\n",
    "# Define video writer parameters\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_file = cv2.VideoWriter('rectangles_area.mp4', fourcc, 30.0, (width, height))\n",
    "\n",
    "\n",
    "# Check if the output video file is open\n",
    "if not output_file.isOpened():\n",
    "    print(\"Error: Unable to open output video file\")\n",
    "    exit()\n",
    "# Main loop\n",
    "while True:\n",
    "    # Wait for a coherent pair of frames: color and depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    # Align the frames\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    # Get the aligned color and depth frames\n",
    "    color_frame = aligned_frames.get_color_frame()\n",
    "    depth_frame = aligned_frames.get_depth_frame()\n",
    "\n",
    "    if not color_frame or not depth_frame:\n",
    "        continue\n",
    "\n",
    "    # Convert color image to numpy array\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    # Convert color image to HSV color space\n",
    "    hsv_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Create a mask for red objects\n",
    "    mask_red = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "    mask_red2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "    mask_red_combined = cv2.bitwise_or(mask_red, mask_red2)\n",
    "\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask_red_combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the largest and second largest red rectangles\n",
    "    largest_rectangle = None\n",
    "    second_largest_rectangle = None\n",
    "    max_area = 0\n",
    "    second_max_area = 0\n",
    "\n",
    "    for contour in contours:\n",
    "        # Find the minimum area rectangle\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "\n",
    "        # Calculate the area of the rectangle\n",
    "        area = cv2.contourArea(box)\n",
    "\n",
    "\n",
    "        # Update the largest, second largest and third largest rectangles if the area is larger\n",
    "        if area > max_area:\n",
    "            third_largest_rectangle = second_largest_rectangle  # New line\n",
    "            third_max_area = second_max_area  # New line\n",
    "            second_largest_rectangle = largest_rectangle\n",
    "            second_max_area = max_area\n",
    "            max_area = area\n",
    "            largest_rectangle = box\n",
    "        elif area > second_max_area:\n",
    "            third_max_area = second_max_area  # New line\n",
    "            third_largest_rectangle = second_largest_rectangle  # New line\n",
    "            second_max_area = area\n",
    "            second_largest_rectangle = box\n",
    "        elif area > third_max_area:  # New condition for third rectangle\n",
    "            third_max_area = area\n",
    "            third_largest_rectangle = box\n",
    "\n",
    "    if largest_rectangle is not None:\n",
    "        # Draw the largest rectangle and its corners on the color image\n",
    "        cv2.drawContours(color_image, [largest_rectangle], 0, (0, 0, 255), 2)\n",
    "        for corner in largest_rectangle:\n",
    "            x, y = corner\n",
    "            cv2.circle(color_image, (x, y), 5, (0, 0, 255), -1)\n",
    "\n",
    "        # Find the middle point of the rectangle\n",
    "        rect_center = np.mean(largest_rectangle, axis=0)\n",
    "        rect_center_x, rect_center_y = rect_center.astype(int)\n",
    "        cv2.circle(color_image, (rect_center_x, rect_center_y), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Get the depth value at the middle point\n",
    "        depth_value1 = depth_frame.get_distance(rect_center_x, rect_center_y)\n",
    "\n",
    "        # Convert from pixel coordinates to real-world coordinates\n",
    "        depth_intrinsics = depth_frame.profile.as_video_stream_profile().intrinsics\n",
    "        point1 = np.array(rs.rs2_deproject_pixel_to_point(depth_intrinsics, [rect_center_x, rect_center_y], depth_value1))\n",
    "\n",
    "        # Stabilize the depth value\n",
    "        mean_depth_value1, last_depth_values1 = stabilization_values(last_depth_values1, depth_value1)\n",
    "        \n",
    "        # Display the stabilized distance on the color image\n",
    "        text = f\"Stabilized Distance 1: {mean_depth_value1:.2f} meters\"\n",
    "        cv2.putText(color_image, text, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    if second_largest_rectangle is not None:\n",
    "        # Draw the second largest rectangle and its corners on the color image\n",
    "        cv2.drawContours(color_image, [second_largest_rectangle], 0, (0, 255, 0), 2)\n",
    "        for corner in second_largest_rectangle:\n",
    "            x, y = corner\n",
    "            cv2.circle(color_image, (x, y), 5, (0, 255, 0), -1)\n",
    "\n",
    "        # Find the middle point of the second rectangle\n",
    "        second_rect_center = np.mean(second_largest_rectangle, axis=0)\n",
    "        second_rect_center_x, second_rect_center_y = second_rect_center.astype(int)\n",
    "        cv2.circle(color_image, (second_rect_center_x, second_rect_center_y), 5, (255, 0, 0), -1)\n",
    "\n",
    "        # Get the depth value at the middle point\n",
    "        depth_value2 = depth_frame.get_distance(second_rect_center_x, second_rect_center_y)\n",
    "\n",
    "        # Convert from pixel coordinates to real-world coordinates\n",
    "        point2 = np.array(rs.rs2_deproject_pixel_to_point(depth_intrinsics, [second_rect_center_x, second_rect_center_y], depth_value2))\n",
    "\n",
    "    # Stabilize the depth value\n",
    "        mean_depth_value2, last_depth_values2 = stabilization_values(last_depth_values2, depth_value2)\n",
    "        \n",
    "        # Display the stabilized distance on the color image\n",
    "        text = f\"Stabilized Distance 2: {mean_depth_value2 :.2f} meters\"\n",
    "        cv2.putText(color_image, text, (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # Calculate the Euclidean distance between the two middle points\n",
    "        distance = np.linalg.norm(point2 - point1)\n",
    "\n",
    "        # Display the Euclidean distance between the two middle points on the color image\n",
    "        distance_text = f\"Distance between points: {distance:.2f} meters\"\n",
    "        cv2.putText(color_image, distance_text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # Draw a line between the two middle points\n",
    "        cv2.line(color_image, (rect_center_x, rect_center_y), (second_rect_center_x, second_rect_center_y), (255, 0, 0), 2)\n",
    "\n",
    "        if third_largest_rectangle is not None:  # New block for third rectangle\n",
    "            cv2.drawContours(color_image, [third_largest_rectangle], 0, (255, 0, 255), 2)\n",
    "            for corner in third_largest_rectangle:\n",
    "                x, y = corner\n",
    "                cv2.circle(color_image, (x, y), 5, (255, 0, 255), -1)\n",
    "            third_rect_center = np.mean(third_largest_rectangle, axis=0)\n",
    "            third_rect_center_x, third_rect_center_y = third_rect_center.astype(int)\n",
    "            cv2.circle(color_image, (third_rect_center_x, third_rect_center_y), 5, (255, 255, 0), -1)\n",
    "            depth_value3 = depth_frame.get_distance(third_rect_center_x, third_rect_center_y)\n",
    "            point3 = np.array(rs.rs2_deproject_pixel_to_point(depth_intrinsics, [third_rect_center_x, third_rect_center_y], depth_value3))\n",
    "            mean_depth_value3, last_depth_values3 = stabilization_values(last_depth_values3, depth_value3)\n",
    "            text = f\"Stabilized Distance 3: {mean_depth_value3:.2f} meters\"\n",
    "            cv2.putText(color_image, text, (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            distance3 = np.linalg.norm(point3 - point1)\n",
    "            distance_text3 = f\"Distance 3: {distance3:.2f} meters\"\n",
    "            cv2.putText(color_image, distance_text3, (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.line(color_image, (rect_center_x, rect_center_y), (third_rect_center_x, third_rect_center_y), (255, 0, 0), 2)\n",
    "\n",
    "            # Calculate and display the distances between all three points\n",
    "            distance_12 = np.linalg.norm(point1 - point2)\n",
    "            distance_23 = np.linalg.norm(point2 - point3)\n",
    "            distance_31 = np.linalg.norm(point3 - point1)\n",
    "            distance_text_12 = f\"Distance between points 1 and 2: {distance_12:.2f} meters\"\n",
    "            distance_text_23 = f\"Distance between points 2 and 3: {distance_23:.2f} meters\"\n",
    "            distance_text_31 = f\"Distance between points 3 and 1: {distance_31:.2f} meters\"\n",
    "            cv2.putText(color_image, distance_text_12, (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(color_image, distance_text_23, (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(color_image, distance_text_31, (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.line(color_image, (second_rect_center_x, second_rect_center_y), (third_rect_center_x, third_rect_center_y), (255, 0, 0), 2)\n",
    "\n",
    "                # Calculate the semi-perimeter\n",
    "            s = (distance_12 + distance_23 + distance_31) / 2\n",
    "\n",
    "            # Calculate the area\n",
    "            area = np.sqrt(s * (s - distance_12) * (s - distance_23) * (s - distance_31))\n",
    "\n",
    "            # Display the area on the color image\n",
    "            area_text = f\"Area between points: {area:.2f} square meters\"\n",
    "            cv2.putText(color_image, area_text, (10, 270), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    # Display the color image\n",
    "    cv2.imshow(\"Color Image\", color_image)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    output_file.write(color_image)\n",
    "\n",
    "pipeline.stop()\n",
    "output_file.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
